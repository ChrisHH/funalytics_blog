[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi I am Christian, living and working in Hamburg.\nIn 2007 I graduated as engineer for Medical Informations and Biomedical Engineering.\nIn 2021 I earned my Masters degree in Big Data and Business Analytics."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FUNAlytics Blog",
    "section": "",
    "text": "Based in the beautiful city of Hamburg, Germany, I find myself deeply engaged in the fields of Data Analytics, Machine Learning, and Artificial Intelligence. These areas, more than just a professional path, are interests that constantly motivate me to learn and grow.\nI often use R for its effectiveness in making sense of complex data, helping turn numbers into meaningful stories.\nMy educational background includes a diploma in Medical Informatics & Biomedical Engineering, obtained in the early 2000s. Furthering my studies, I completed a Master‚Äôs in Big Data and Business Analytics in 2021. In my career, particularly in market research, I‚Äôve gained a broad understanding, from basic principles to more advanced methods.\nThis blog shares some of the analyses I do in my spare time, and occasionally, I explore topics in Avionics, another area of interest. ‚úàÔ∏èÔ∏è\nTo get started, you can check out my blog."
  },
  {
    "objectID": "about.html#hey-this-is-me",
    "href": "about.html#hey-this-is-me",
    "title": "About",
    "section": "",
    "text": "Hi I am Christian, living and working in Hamburg.\nIn 2007 I graduated as engineer for Medical Informations and Biomedical Engineering.\nIn 2021 I earned my Masters degree in Big Data and Business Analytics."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Disentangling Effects: The Secret Behind Marketing Mix Models\n\n\n\nR\n\n\nMarketing Mix Modell\n\n\nDisentangle Effects\n\n\nIce Cream\n\n\n\n\n\n\n\nChristian Jaehnert\n\n\nMay 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nMaximizing Loyalty Points\n\n\n\nR\n\n\nggplot\n\n\ntidyverse\n\n\nbargain\n\n\nsaving money\n\n\nloyalty points\n\n\n\n\n\n\n\nChristian Jaehnert\n\n\nDec 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nFlight LH790 (MUC - SIN)\n\n\n\nR\n\n\nggplot\n\n\ntidyverse\n\n\naviation\n\n\nMUC\n\n\nSIN\n\n\nflights\n\n\n\n\n\n\n\nChristian Jaehnert\n\n\nNov 27, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#hi-and-welcome-to-my-blog",
    "href": "index.html#hi-and-welcome-to-my-blog",
    "title": "FUNAlytics Blog",
    "section": "",
    "text": "Browse through the tiles on your interest. You can also choose the filter section on the right!"
  },
  {
    "objectID": "index.html#latest-blog-posts",
    "href": "index.html#latest-blog-posts",
    "title": "FUNAlytics Blog",
    "section": "Latest Blog Posts",
    "text": "Latest Blog Posts"
  },
  {
    "objectID": "index.html#hi-im-christian",
    "href": "index.html#hi-im-christian",
    "title": "FUNAlytics Blog",
    "section": "",
    "text": "Based in the beautiful city of Hamburg, Germany, I find myself deeply engaged in the fields of Data Analytics, Machine Learning, and Artificial Intelligence. These areas, more than just a professional path, are interests that constantly motivate me to learn and grow.\nI often use R for its effectiveness in making sense of complex data, helping turn numbers into meaningful stories.\nMy educational background includes a diploma in Medical Informatics & Biomedical Engineering, obtained in the early 2000s. Furthering my studies, I completed a Master‚Äôs in Big Data and Business Analytics in 2021. In my career, particularly in market research, I‚Äôve gained a broad understanding, from basic principles to more advanced methods.\nThis blog shares some of the analyses I do in my spare time, and occasionally, I explore topics in Avionics, another area of interest. ‚úàÔ∏èÔ∏è\nTo get started, you can check out my blog."
  },
  {
    "objectID": "posts/2023-11-24-Flight-LH790/index.html",
    "href": "posts/2023-11-24-Flight-LH790/index.html",
    "title": "Flight LH790 (MUC - SIN)",
    "section": "",
    "text": "Hello, it‚Äôs been a while since my last post! You remember the bears in Canada? üêª\nHowever, both this post and the last one share a common theme: they‚Äôre about my upcoming travels.\nI‚Äôm eagerly anticipating my trip to Singapore. As a fan of the city, I want to start enjoying it right from the moment of my arrival, which means catching a glimpse of the skyline as the plane approaches Changi Airport.\nGiven the airport is located to the east of the city, a south-west approach typically offers the most scenic vistas. The question is: What is the likelihood that I will see this view, sitting on the left side of the plane?\n\n\n\nSource: Swapnil Bapat on Unsplash.com\n\n\nThankfully, data is here to help! I invite you to join me on this analytical journey. ‚úàÔ∏è"
  },
  {
    "objectID": "posts/2023-11-24-Flight-LH790/index.html#introduction",
    "href": "posts/2023-11-24-Flight-LH790/index.html#introduction",
    "title": "Flight LH790 (MUC - SIN)",
    "section": "",
    "text": "Hello, it‚Äôs been a while since my last post! You remember the bears in Canada? üêª\nHowever, both this post and the last one share a common theme: they‚Äôre about my upcoming travels.\nI‚Äôm eagerly anticipating my trip to Singapore. As a fan of the city, I want to start enjoying it right from the moment of my arrival, which means catching a glimpse of the skyline as the plane approaches Changi Airport.\nGiven the airport is located to the east of the city, a south-west approach typically offers the most scenic vistas. The question is: What is the likelihood that I will see this view, sitting on the left side of the plane?\n\n\n\nSource: Swapnil Bapat on Unsplash.com\n\n\nThankfully, data is here to help! I invite you to join me on this analytical journey. ‚úàÔ∏è"
  },
  {
    "objectID": "posts/2023-11-24-Flight-LH790/index.html#data",
    "href": "posts/2023-11-24-Flight-LH790/index.html#data",
    "title": "Flight LH790 (MUC - SIN)",
    "section": "Data",
    "text": "Data\nMy flight to Singapore is with Lufthansa, departing from Munich. I‚Äôll be on flight LH790, a service offered six times per week using the very fuel-efficient A350.\nAviation is a passion of mine, so I have a membership at www.flightradar24.com. ü§ì This allows the download of the flight path for each flight over the past 365 days. I downloaded the data for the last 80 days‚Äô flights of LH790. Let‚Äôs first look at the variables and the date range.\n\nVariablesFlight Dates\n\n\n\n\nRows: 115,502\nColumns: 13\n$ timestamp     &lt;dbl&gt; 1691784874, 1691784882, 1691784892, 1691784903, 16917849‚Ä¶\n$ utc           &lt;dttm&gt; 2023-08-11 20:14:34, 2023-08-11 20:14:42, 2023-08-11 20‚Ä¶\n$ callsign      &lt;chr&gt; \"DLH790\", \"DLH790\", \"DLH790\", \"DLH790\", \"DLH790\", \"DLH79‚Ä¶\n$ lat           &lt;dbl&gt; 48.35789, 48.35788, 48.35789, 48.35790, 48.35798, 48.358‚Ä¶\n$ lon           &lt;dbl&gt; 11.79256, 11.79278, 11.79301, 11.79330, 11.79355, 11.793‚Ä¶\n$ altitude      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,‚Ä¶\n$ speed         &lt;dbl&gt; 3, 4, 4, 4, 4, 4, 0, 0, 4, 5, 6, 6, 12, 13, 14, 15, 15, ‚Ä¶\n$ direction     &lt;dbl&gt; 261, 255, 244, 225, 208, 182, 174, 174, 174, 174, 174, 1‚Ä¶\n$ file_name     &lt;chr&gt; \"LH790_318ce2d1.csv\", \"LH790_318ce2d1.csv\", \"LH790_318ce‚Ä¶\n$ weekday       &lt;ord&gt; Fri, Fri, Fri, Fri, Fri, Fri, Fri, Fri, Fri, Fri, Fri, F‚Ä¶\n$ weekday_start &lt;ord&gt; Fri, Fri, Fri, Fri, Fri, Fri, Fri, Fri, Fri, Fri, Fri, F‚Ä¶\n$ date_start    &lt;date&gt; 2023-08-11, 2023-08-11, 2023-08-11, 2023-08-11, 2023-08‚Ä¶\n$ label         &lt;chr&gt; \"LH790 2023-08-11\", \"LH790 2023-08-11\", \"LH790 2023-08-1‚Ä¶\n\n\n\n\n\n\n [1] \"2023-08-11\" \"2023-08-13\" \"2023-08-14\" \"2023-08-15\" \"2023-08-16\"\n [6] \"2023-08-17\" \"2023-08-18\" \"2023-08-20\" \"2023-08-21\" \"2023-08-22\"\n[11] \"2023-08-23\" \"2023-08-24\" \"2023-08-25\" \"2023-08-27\" \"2023-08-28\"\n[16] \"2023-08-29\" \"2023-08-30\" \"2023-08-31\" \"2023-09-01\" \"2023-09-03\"\n[21] \"2023-09-04\" \"2023-09-06\" \"2023-09-07\" \"2023-09-08\" \"2023-09-10\"\n[26] \"2023-09-11\" \"2023-09-13\" \"2023-09-14\" \"2023-09-15\" \"2023-09-17\"\n[31] \"2023-09-18\" \"2023-09-20\" \"2023-09-21\" \"2023-09-22\" \"2023-09-24\"\n[36] \"2023-09-25\" \"2023-09-27\" \"2023-09-28\" \"2023-09-29\" \"2023-10-01\"\n[41] \"2023-10-02\" \"2023-10-04\" \"2023-10-05\" \"2023-10-06\" \"2023-10-08\"\n[46] \"2023-10-09\" \"2023-10-11\" \"2023-10-12\" \"2023-10-13\" \"2023-10-15\"\n[51] \"2023-10-16\" \"2023-10-18\" \"2023-10-19\" \"2023-10-22\" \"2023-10-23\"\n[56] \"2023-10-25\" \"2023-10-26\" \"2023-10-27\" \"2023-10-29\" \"2023-10-30\"\n[61] \"2023-10-31\" \"2023-11-01\" \"2023-11-02\" \"2023-11-03\" \"2023-11-05\"\n[66] \"2023-11-06\" \"2023-11-07\" \"2023-11-08\" \"2023-11-09\" \"2023-11-10\"\n[71] \"2023-11-12\" \"2023-11-13\" \"2023-11-14\" \"2023-11-15\" \"2023-11-16\"\n[76] \"2023-11-17\" \"2023-11-19\" \"2023-11-20\" \"2023-11-21\" \"2023-11-22\"\n\n\n\n\n\nThe data is already quite impressive. From just 80 flights, I‚Äôve gathered 115,502 data points, averaging about 1,444 per flight. So, what do we have?\nThe timestamp and UTC provide the time information. Latitude (Lat) and Longitude (Lon) show the position of the plane at a certain timestamp/UTC. There‚Äôs also data on speed (in knots), altitude (in feet), and direction (heading) for that moment.\nI‚Äôve already derived some additional variables that might be useful or interesting, such as the weekday, the weekday of departure from Munich (since the date line is crossed during the flight), and a unique label for each flight.\nThe following analysis is based on the LH790 flights from 2023-08-11 to 2023-11-22. That is a difference of 103 days. But since the connection is not offered every day, we only look into the last 80 flights in this date range.\nNow its time to jump into the data!"
  },
  {
    "objectID": "posts/2023-11-24-Flight-LH790/index.html#punctuality-of-departure",
    "href": "posts/2023-11-24-Flight-LH790/index.html#punctuality-of-departure",
    "title": "Flight LH790 (MUC - SIN)",
    "section": "Punctuality of departure",
    "text": "Punctuality of departure\nLet‚Äôs begin with a quick review of the departure punctuality. The flight is scheduled to depart at 10 PM from Munich. I calculated the difference between this time and the actual take-off time, which is determined by the first waypoint (time) exceeding 1000 feet.\n\n\n\n\n\nFortunately, the histogram indicates that only a few flights have delays exceeding one hour. The average delay is approximately 36.4 minutes. This seems quite reasonable for a 12-hour flight, especially considering that the STD refers to the time when the plane is pushed back. Thus, the ‚Äúdelay‚Äù observed here actually encompasses the time taken for pushing back and taxiing. In conclusion, there is no need to be concerned about significant delays."
  },
  {
    "objectID": "posts/2023-11-24-Flight-LH790/index.html#speed-altitude",
    "href": "posts/2023-11-24-Flight-LH790/index.html#speed-altitude",
    "title": "Flight LH790 (MUC - SIN)",
    "section": "Speed & Altitude",
    "text": "Speed & Altitude\nLet‚Äôs scatter both variables, speed and altitude, from the 80 flights.\n\n\n\n\n\nThe plot of speed versus altitude is intriguing. It clearly shows takeoff and landing phases (speed &gt; 0 at altitude = 0). It appears the plane takes off at around 150 knots, as that‚Äôs when altitude begins to increase (vice versa for landing).\nThere seems to be a linear relationship between speed and altitude, which is intuitive. But why does it form a funnel shape? This warrants further investigation. My theory is that there‚Äôs a different relationship (scatter) during the three flight stages:\n\nTakeoff/Climb\nCruise\nLanding/Descent\n\nI don‚Äôt have stage information in the dataset, so I derived it, after removing some of the strange points in the scatter plot (very low speed at high altitude). See the following code.\n\n\nClick here to unhide/hide the code.\nall_data &lt;- all_data %&gt;% \n  filter(!(altitude &gt; 100 & speed &lt; 100)) %&gt;% \n  filter(!(altitude &gt; 30000 & speed &lt; 400)) %&gt;% \n  group_by(file_name) %&gt;% \n  arrange(timestamp) %&gt;%\n  mutate(altitude_before = lag(altitude, default = 0),\n         altitude_after = lead(altitude))  %&gt;% \n  filter(!(altitude == 0 & altitude_before == 0 & altitude_after == 0)) \n\nall_data &lt;- all_data %&gt;% \n  group_by(label) %&gt;% \n  arrange(utc, .by_group = TRUE) %&gt;% \n  mutate(startzeit = utc[1], \n         flugdauer = difftime(utc, startzeit, units = \"mins\"),\n         flugdauer = as.numeric(flugdauer))\n\n\ntakeoff_threshold = 10    \nlanding_threshold = -10\n\nall_data &lt;- all_data %&gt;% \n  mutate(gradient = c(NA, diff(altitude) / diff(flugdauer)),\n         smooth_gradient = rollmean(gradient, 5, fill = NA)) %&gt;% \n  mutate(phase = case_when(\n    smooth_gradient &gt; takeoff_threshold ~ 'Climb',\n    smooth_gradient &lt; landing_threshold ~ 'Descend',\n    TRUE ~ 'Cruise'\n  ))\n\n\nWhats going on in the code? After cleaning up of the anomalies in the data, I focused on calculating the relative length of the flight since takeoff. To clarify, I‚Äôm considering ‚Äòtakeoff‚Äô as the last moment when the altitude is zero and eliminating all prior data points, effectively excluding the taxiing phase (same applies for the landing).\nThe next step is to calculate the gradient, which involves correlating the change in altitude with the change in the relative length of the flight. The sign of this gradient indicates whether the plane is ascending or descending between two points. After this, I smooth out the gradient for a clearer analysis.\nLet‚Äôs now revisit the plot, this time analyzing it by the flight phase.\n\n\n\n\n\nThe results are fascinating! The climb phase (red) requires higher speed to gain altitude, as governed by physical laws, as it sits more towards the right side (higher speed).\nWhat‚Äôs particularly striking is the precision with which the plane maintains altitude at different speeds during the cruise phase (green lines)."
  },
  {
    "objectID": "posts/2023-11-24-Flight-LH790/index.html#altitude-and-duration",
    "href": "posts/2023-11-24-Flight-LH790/index.html#altitude-and-duration",
    "title": "Flight LH790 (MUC - SIN)",
    "section": "Altitude and Duration",
    "text": "Altitude and Duration\nI need to take a closer look at this aspect of maintaining stable altitude.\nTherefore, I am plotting the plane‚Äôs altitude against flight time (measured in minutes).\nI will present a summary encompassing all flights, and for enhanced clarity, I will also showcase randomly selected flights throughout this article (you can switch between the different views using the tabs).\n\nAll FlightsRandom Flights\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt‚Äôs amazing to see how the plane maintains a consistent altitude over an extended period of time. Yes, I‚Äôm aware there are minor deviations in altitude, or even significant ones during turbulence. The plot here is somewhat smoothed out due to the resolution of the measurement and also the range of the X- and Y-axis, but I‚Äôm still impressed.\n\n\n\n\n\n\nNote\n\n\n\nWhat can also be observed is that sometimes the altitude profile has gaps. This is due to the absence of data points in some instances. The reason for this is that Flightradar24 cannot track signals in certain areas of the world (e.g.¬†ocean areas).\n\n\nUpon further analysis, I noticed an anomaly on the flight dated November 19th. A quick check on Flightradar24 revealed that on that day, the plane was diverted to Kuala Lumpur after two unsuccessful landing attempts due to bad weather at the airport. I‚Äôll exclude this flight from the rest of the analysis."
  },
  {
    "objectID": "posts/2023-11-24-Flight-LH790/index.html#approaching-singapore",
    "href": "posts/2023-11-24-Flight-LH790/index.html#approaching-singapore",
    "title": "Flight LH790 (MUC - SIN)",
    "section": "Approaching Singapore",
    "text": "Approaching Singapore\nLet‚Äôs now turn our attention to the initial question regarding the likelihood of having the best view of Singapore‚Äôs skyline, and take a closer look at the local conditions in more detail.\n\n\n\nSource: Google Maps\n\n\nAs indicated on the map and mentioned earlier, if the approach is from the southwest (shown by the purple arrow), then the left side of the plane provides a good view of the skyline. On the other hand, for a northeast approach (marked by the orange arrow), it‚Äôs recommended to sit on the right side to catch a glimpse of the city, even if it‚Äôs not the full, impressive skyline.\nWhat needs to be done now is to determine the approach direction for each flight in order to calculate the likelihood of getting the best view. How do I do that?\nFrom the flight path I examined the final descent phase, specifically when the plane was below 2,000 feet (~ 600 m) in altitude, because at that stage I would expect (and hope üòÉ) that the plane is already fully aligned with the runway! Let‚Äôs first see if this expectation holds true!\n\nAll FlightsRandom Flights\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe yellow point marks the location of the renowned Marina Bay Sands, while the green dot signifies the official location of Singapore Airport. It is very evident that at an altitude of 2,000 feet, the aircraft is already perfectly aligned with the runway (blue points form a perfect line). Additionally, it is observable that there is a singular direction offering a prime view of the skyline: the approach from the southwest (like we already know).\n\n\n\n\n\n\nNote\n\n\n\nThere is multiple runways at Singapore, thats why the line is shifted from day to day.\n\n\nNow, all I need to do is classify each approach to easily tally them up. And here‚Äôs the concept: if the average latitude of the approach is less than the latitude of Singapore airport, then the approach is likely from the northeast. Conversely, if it‚Äôs higher, the approach is probably from the southeast. This must be adjusted to the specific airport (could be different if there are crossing runways). Let‚Äôs calculate and see what the results show.\n\n\nClick here to unhide/hide the code.\nflights_direction &lt;- all_data %&gt;%\n  group_by(label) %&gt;% \n  filter(phase == \"Descend\" & altitude &lt; 2000) %&gt;% \n  group_by(label) %&gt;%\n  summarize(approach_direction = if_else(mean(lat) &gt; 1.359167, \n                                         'north-east', \n                                         'south-west'))\n\n\nNow, let‚Äôs proceed to verify if the ‚Äúclassification‚Äù is accurate by conducting a graphical inspection (this time without the Marina Bay Sands, but only the airport as a green point).\n\nAll FlightsRandom FlightsResult\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo clarify the legend: the approach always refers to the incoming direction. So, ‚Äúsouth-west‚Äù means that the approach is being made from the southwest direction (as you can see in the plot). As mentioned earlier, the approach from the southwest offers the best view of the skyline, but it turns out, disappointingly, that only ~ 25% of the 80 flights are approached from this direction.\n\nWhat a pitty üò•."
  },
  {
    "objectID": "posts/2023-11-24-Flight-LH790/index.html#conclusion",
    "href": "posts/2023-11-24-Flight-LH790/index.html#conclusion",
    "title": "Flight LH790 (MUC - SIN)",
    "section": "Conclusion",
    "text": "Conclusion\nI thoroughly enjoyed this quick analysis again. I hope you found it enjoyable too! I learned: I don‚Äôt need to worry about delays. I‚Äôm definitely planning to sit on the left side of the plane, fingers crossed for that 25% chance. ü§û\nIn my next post I will remain on this flight and try to identify holding patterns during the descent towards Singapore‚Äôs Changi airport. Stay tuned!"
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "test",
    "section": "",
    "text": "Bla Bla"
  },
  {
    "objectID": "posts/2023-12-03-Couponing/index.html",
    "href": "posts/2023-12-03-Couponing/index.html",
    "title": "Maximizing Loyalty Points",
    "section": "",
    "text": "Imagine yourself at the checkout counter of a supermarket with a long line of unpatient customers behind you. The register shows your total as ‚Ç¨31.28.\n\n\n\nSource: DALL‚Ä¢E\n\n\nIn this situation, which coupon of the following would you choose in order to maximize your loyalty points with the supermarket (normally, you get one point for every cent)?\n\nTriple points for a purchase of 15 Euros or more\n5,000 extra points for a purchase of 20 Euros or more\nQuintuple points for a purchase of 25 Euros or more\n10,000 extra points for a purchase of 30 Euros or more\n\nWould you be tempted to select the coupon offering 10,000 extra points, simply because the number of extra points is impressively large and you‚Äôve met the required threshold? Alternatively, is the quintuple points option a smarter choice? Quick calculations could resolve this dilemma, but remember, a queue of customers is already eyeing you impatiently from behind. Their expectant gazes add pressure to your decision-making process.\nOh yes, these coupons are actually available at a supermarket right now. I didn‚Äôt make that up. üòâ\nBut I experienced this situation firsthand.\nToday, we‚Äôll delve into a graphical solution of the question and, as an added benefit, examine a calculated decision tree designed to guide you in selecting the most suitable coupon for this particular scenario. Lets jump into the quick and practical analysis!"
  },
  {
    "objectID": "posts/2023-12-03-Couponing/index.html#attention-points-collectors",
    "href": "posts/2023-12-03-Couponing/index.html#attention-points-collectors",
    "title": "Couponing",
    "section": "",
    "text": "Today‚Äôs post is quick yet practical, tailored for all loyalty point enthusiasts.\nIt‚Äôs that time of year when retailers compete fiercely for consumer loyalty, enticing shoppers to choose their stores. This season is ripe with opportunities to redeem coupons for loyalty programs. I‚Äôve recently come across some notable examples, where one could choose from one of the four options during checkout:\n\nTriple points for a purchase of 15 Euros or more\n5,000 extra points for a purchase of 20 Euros or more\nQuintuple points for a purchase of 25 Euros or more\n10,000 extra points for a purchase of 30 Euros or more"
  },
  {
    "objectID": "posts/2023-12-03-Couponing/index.html#situation-at-checkout",
    "href": "posts/2023-12-03-Couponing/index.html#situation-at-checkout",
    "title": "Maximizing Loyalty Points",
    "section": "",
    "text": "Imagine yourself at the checkout counter of a supermarket with a long line of unpatient customers behind you. The register shows your total as ‚Ç¨31.28.\n\n\n\nSource: DALL‚Ä¢E\n\n\nIn this situation, which coupon of the following would you choose in order to maximize your loyalty points with the supermarket (normally, you get one point for every cent)?\n\nTriple points for a purchase of 15 Euros or more\n5,000 extra points for a purchase of 20 Euros or more\nQuintuple points for a purchase of 25 Euros or more\n10,000 extra points for a purchase of 30 Euros or more\n\nWould you be tempted to select the coupon offering 10,000 extra points, simply because the number of extra points is impressively large and you‚Äôve met the required threshold? Alternatively, is the quintuple points option a smarter choice? Quick calculations could resolve this dilemma, but remember, a queue of customers is already eyeing you impatiently from behind. Their expectant gazes add pressure to your decision-making process.\nOh yes, these coupons are actually available at a supermarket right now. I didn‚Äôt make that up. üòâ\nBut I experienced this situation firsthand.\nToday, we‚Äôll delve into a graphical solution of the question and, as an added benefit, examine a calculated decision tree designed to guide you in selecting the most suitable coupon for this particular scenario. Lets jump into the quick and practical analysis!"
  },
  {
    "objectID": "posts/2023-12-03-Couponing/index.html#identifying-the-best-coupon",
    "href": "posts/2023-12-03-Couponing/index.html#identifying-the-best-coupon",
    "title": "Maximizing Loyalty Points",
    "section": "Identifying the Best Coupon",
    "text": "Identifying the Best Coupon\nFirst, let‚Äôs create a dataframe populated with values ranging from ‚Ç¨0 to ‚Ç¨100, in increments of ‚Ç¨0.01. As mentioned already, the number of loyalty points typically awarded corresponds to the payment amount in cents. Then, I will define the four coupons as variables by applying the math of the mechanic. At the end, I determine the best coupon for each purchase value and store it in another variable.\n\n\nClick here to unhide/hide the code.\nwert &lt;- tibble(purchase_value = seq(0.01, 100,0.01))\nwert &lt;- wert %&gt;% \n  mutate(points = purchase_value * 100) %&gt;% \n  mutate(points_5000_from_20 = if_else(purchase_value &gt;=20, points + 5000, points),\n         points_10000_from_30 = if_else(purchase_value &gt;=30, points + 10000, points),\n         points_5x_from_25 = if_else(purchase_value &gt;= 25, 5*points, points),\n         points_3x_from_15 = if_else(purchase_value &gt;=15, 3*points, points)) %&gt;% \n  mutate(best_value = pmax(points_5000_from_20, points_10000_from_30, points_5x_from_25, points_3x_from_15))\n\n\nLets have a glimpse on the data frame.\n\n\nRows: 10,000\nColumns: 7\n$ purchase_value       &lt;dbl&gt; 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0‚Ä¶\n$ points               &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15‚Ä¶\n$ points_5000_from_20  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15‚Ä¶\n$ points_10000_from_30 &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15‚Ä¶\n$ points_5x_from_25    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15‚Ä¶\n$ points_3x_from_15    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15‚Ä¶\n$ best_value           &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15‚Ä¶\n\n\nThat‚Äôs all we need. I‚Äôve now plotted the loyalty points against purchase value to visually illustrate how each coupon performs. Let‚Äôs take a graphical look at the effectiveness of each offer!\n\nSolutionZoom In\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the plot, the dashed line represents loyalty points earned per purchase value without using a coupon.\nNow, let‚Äôs delve into the coupon details ‚Äì it‚Äôs quite intriguing!\nSurprise: The coupon offering ‚Äò10,000 extra points for purchases over ‚Ç¨30‚Äô (indicated by the red line) is not advantageous for any purchase value. üí° Hence, one might consider discarding this coupon right away, especially if new coupon booklets are regularly available.\nThe coupons providing ‚ÄòTriple points for a purchase of 15 Euros or more‚Äô (blue line) and ‚Äò5,000 extra points for purchases over ‚Ç¨20‚Äô (green line) benefits customers only within a very narrow spending range¬†of ‚Ç¨5. Let‚Äôs take a brief look at the intersection around ‚Ç¨25, where both lines intersect. Is it irrelevant which coupon one uses there? (Keep in mind, this post is a goldmine for those on a mission to supercharge their loyalty points! üöÄüòâ)\nThe answer: Not at all! The zoom shows that. Also, just before the next threshold, the coupon ‚Äò5,000 extra points for purchases over ‚Ç¨20‚Äô is preferable. At a spend value of ‚Ç¨24.99 this coupon gives 2 loyalty points more üòâ\nFrom ‚Ç¨25 on the coupon ‚ÄòQuintuple points for a purchase of 25 Euros or more‚Äô is the best option!"
  },
  {
    "objectID": "posts/2023-12-03-Couponing/index.html#all-that-glitters-is-not-gold",
    "href": "posts/2023-12-03-Couponing/index.html#all-that-glitters-is-not-gold",
    "title": "Couponing",
    "section": "All that glitters is not gold",
    "text": "All that glitters is not gold\nNow, let‚Äôs already take a graphical look at how each coupon performs!\n\n\n\n\n\nIn the plot, the dashed line represents loyalty points earned per purchase value without using a coupon.\nNow, let‚Äôs delve into the coupon details ‚Äì it‚Äôs quite intriguing!\nThe coupon offering ‚Äò10,000 extra points for purchases over ‚Ç¨30‚Äô (indicated by the red line) is not advantageous for any purchase value. Hence, one might consider discarding this coupon right away, especially if new coupon booklets are regularly available. Similarly, the coupon providing ‚Äò5,000 extra points for purchases over ‚Ç¨20‚Äô benefits customers only within a very narrow spending range.\nAnother observation is that coupons offering a relative increase in extra loyalty points perform better. As the purchase value increases, the gap between standard and extra points widens.\nA practical guideline might be to prioritize coupons that offer increased loyalty points in proportion to the amount spent. However, to validate this strategy, let‚Äôs proceed with running the decision tree.\n\n\n\n\n\nHave fun cutting the decision tree out and tucking them into your wallet üòÉ\nUntil next time!"
  },
  {
    "objectID": "posts/2023-12-03-Couponing/index.html#decision-tree",
    "href": "posts/2023-12-03-Couponing/index.html#decision-tree",
    "title": "Maximizing Loyalty Points",
    "section": "Decision Tree",
    "text": "Decision Tree\nThat‚Äôs of course all too complicated to remember. Therefore, as a bonus, we now turn to the decision tree.\n\n\nClick here to unhide/hide the code.\nlibrary(rpart)\nlibrary(rpart.plot)\n\n\ntree &lt;- rpart(best_option ~ purchase_value, \n              data = wert , \n              method = \"class\")\n\n\nrpart.plot(tree, fallen.leaves = TRUE, under = TRUE, type = 5, legend.y = NA)\n\n\n\n\n\n\n\n\n\nHave fun cutting the decision tree out and tucking them into your wallet üòÉ\nUntil next time! üôã‚Äç‚ôÇÔ∏è"
  },
  {
    "objectID": "index.html#check-my-latest-blogposts",
    "href": "index.html#check-my-latest-blogposts",
    "title": "FUNAlytics Blog",
    "section": "Check my latest blogposts",
    "text": "Check my latest blogposts"
  },
  {
    "objectID": "index.html#my-latest-blogposts",
    "href": "index.html#my-latest-blogposts",
    "title": "FUNAlytics Blog",
    "section": "My Latest Blogposts",
    "text": "My Latest Blogposts"
  },
  {
    "objectID": "posts/2024-11-14-MMM-Variance/index.html",
    "href": "posts/2024-11-14-MMM-Variance/index.html",
    "title": "Disentangling Effects: The Secret Behind Marketing Mix Models",
    "section": "",
    "text": "The Magic of Variance in Marketing Mix Modeling\nMarketing Mix Modeling (MMM) is a statistical technique in econometrics that quantifies the impact of various marketing and sales activities on sales. It also incorporates external factors that are typically beyond a company‚Äôs control, such as weather, holidays, or competitive activities.\nSince I work in the area of MMM, I‚Äôm often asked a similar question:\nHow can MMM disentangle the effects of various factors, like advertising campaigns across multiple channels, POS promotions, or weather?\nThe answer lies in the concept of¬†variance. By capturing and analyzing the variation in data, MMM can attribute changes in sales to specific factors like advertising, price changes, or external conditions such as weather. In turn this explains why a MMM is typically very greedy on data!\nVariance is essentially the ‚Äúspread‚Äù or ‚Äúdispersion‚Äù in data. When factors such as advertising spend, product pricing, and weather fluctuate, they create unique ‚Äúpatterns‚Äù in the data. These patterns allow MMM to distinguish the unique contribution of each factor to the overall sales. The model then estimates each variable‚Äôs impact by looking at how variations in these variables align with variations in sales over time.\nTo demonstrate this in a simple example, let‚Äôs take an ice cream company and see how MMM might work to disentangle the effects of advertising, temperature, and price.\n\n\nExample: Ice Cream Sales and the Magic of Variance\nIn this example, we‚Äôll simulate weekly ice cream sales data over three years (152 weeks) along with three explanatory variables: advertising spend, average weekly temperature, and the price of ice cream.\n\n\n\nCall:\nlm(formula = Sales ~ Temperature + Ad_Spend + Price, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-282.075  -62.825   -4.733   73.525  233.725 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.071e+02  6.864e+01   8.845 2.53e-15 ***\nTemperature  1.658e+01  1.754e+00   9.451  &lt; 2e-16 ***\nAd_Spend     2.671e-02  6.806e-03   3.925 0.000133 ***\nPrice       -1.514e+02  1.768e+01  -8.564 1.30e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 94.63 on 148 degrees of freedom\nMultiple R-squared:  0.5662,    Adjusted R-squared:  0.5574 \nF-statistic: 64.39 on 3 and 148 DF,  p-value: &lt; 2.2e-16\n\n\n1+1"
  },
  {
    "objectID": "posts/2024-11-14-MMM-Variance_Explained/index.html",
    "href": "posts/2024-11-14-MMM-Variance_Explained/index.html",
    "title": "Disentangling Effects: The Secret Behind Marketing Mix Models",
    "section": "",
    "text": "The Magic of Variance in Marketing Mix Modeling\nMarketing Mix Modeling (MMM) is a statistical technique in econometrics that quantifies the impact of various marketing and sales activities on sales. It also incorporates external factors that are typically beyond a company‚Äôs control, such as weather, holidays, or competitive activities.\nSince I work in the area of MMM, I‚Äôm often asked a similar question:\nHow can MMM disentangle the effects of various factors, like advertising campaigns across multiple channels, POS promotions, or weather?\nThe answer lies in the concept of¬†variance. By capturing and analyzing the variation in data, MMM can attribute changes in sales to specific factors like advertising, price changes, or external conditions such as weather. In turn this explains why a MMM is typically very greedy on data!\nVariance is essentially the ‚Äúspread‚Äù or ‚Äúdispersion‚Äù in data. When factors such as advertising spend, product pricing, and weather fluctuate, they create unique ‚Äúpatterns‚Äù in the data. These patterns allow MMM to distinguish the unique contribution of each factor to the overall sales. The model then estimates each variable‚Äôs impact by looking at how variations in these variables align with variations in sales over time.\nTo demonstrate this in a simple example, let‚Äôs take an ice cream company and see how MMM might work to disentangle the effects of advertising, temperature, and price.\n\n\nExample: Ice Cream Sales and the Magic of Variance\nIn this example, we‚Äôll simulate weekly ice cream sales data over three years (152 weeks) along with three explanatory variables: advertising spend, average weekly temperature, and the price of ice cream.\n\n\n\nCall:\nlm(formula = Sales ~ Temperature + Ad_Spend + Price, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-282.075  -62.825   -4.733   73.525  233.725 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.071e+02  6.864e+01   8.845 2.53e-15 ***\nTemperature  1.658e+01  1.754e+00   9.451  &lt; 2e-16 ***\nAd_Spend     2.671e-02  6.806e-03   3.925 0.000133 ***\nPrice       -1.514e+02  1.768e+01  -8.564 1.30e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 94.63 on 148 degrees of freedom\nMultiple R-squared:  0.5662,    Adjusted R-squared:  0.5574 \nF-statistic: 64.39 on 3 and 148 DF,  p-value: &lt; 2.2e-16\n\n\n1+1"
  },
  {
    "objectID": "posts/2024-11-14-Variance-in-MMM/index.html",
    "href": "posts/2024-11-14-Variance-in-MMM/index.html",
    "title": "Disentangling Effects: The Secret Behind Marketing Mix Models",
    "section": "",
    "text": "The Magic of Variance in Marketing Mix Modeling\nMarketing Mix Modeling (MMM) is a statistical technique in econometrics that quantifies the impact of various marketing and sales activities on sales. It also incorporates external factors that are typically beyond a company‚Äôs control, such as weather, holidays, or competitive activities.\nSince I work in the area of MMM, I‚Äôm often asked a similar question:\nHow can MMM disentangle the effects of various factors, like advertising campaigns across multiple channels, POS promotions, or weather?\nThe answer lies in the concept of¬†variance. By capturing and analyzing the variation in data, MMM can attribute changes in sales to specific factors like advertising, price changes, or external conditions such as weather. In turn this explains why a MMM is typically very greedy on data!\nVariance is essentially the ‚Äúspread‚Äù or ‚Äúdispersion‚Äù in data. When factors such as advertising spend, product pricing, and weather fluctuate, they create unique ‚Äúpatterns‚Äù in the data. These patterns allow MMM to distinguish the unique contribution of each factor to the overall sales. The model then estimates each variable‚Äôs impact by looking at how variations in these variables align with variations in sales over time.\nTo demonstrate this in a simple example, let‚Äôs take an ice cream company and see how MMM might work to disentangle the effects of advertising, temperature, and price.\n\n\nExample: Ice Cream Sales and the Magic of Variance\nIn this example, we‚Äôll simulate weekly ice cream sales data over three years (152 weeks) along with three explanatory variables: advertising spend, average weekly temperature, and the price of ice cream.\n\n\n\nCall:\nlm(formula = Sales ~ Temperature + Ad_Spend + Price, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-282.075  -62.825   -4.733   73.525  233.725 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.071e+02  6.864e+01   8.845 2.53e-15 ***\nTemperature  1.658e+01  1.754e+00   9.451  &lt; 2e-16 ***\nAd_Spend     2.671e-02  6.806e-03   3.925 0.000133 ***\nPrice       -1.514e+02  1.768e+01  -8.564 1.30e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 94.63 on 148 degrees of freedom\nMultiple R-squared:  0.5662,    Adjusted R-squared:  0.5574 \nF-statistic: 64.39 on 3 and 148 DF,  p-value: &lt; 2.2e-16\n\n\n1+1"
  },
  {
    "objectID": "posts/2024-11-14-Variance-Magic-MMM/index.html",
    "href": "posts/2024-11-14-Variance-Magic-MMM/index.html",
    "title": "Disentangling Effects: The Secret Behind Marketing Mix Models",
    "section": "",
    "text": "The Magic of Variance in Marketing Mix Modeling\nMarketing Mix Modeling (MMM) is a statistical technique in econometrics that quantifies the impact of various marketing and sales activities on sales of a company. It also incorporates external factors that are typically beyond a company‚Äôs control, such as weather, holidays, or competitive activities.\nSince I work in the area of MMM, I‚Äôm often asked a similar question:\nHow can MMM actually disentangle the effects of various factors, like advertising campaigns across multiple media channels, POS promotions, or weather? How does this ‚Äúdisentangling‚Äù work?\nThe answer lies in the concept of¬†variance. By capturing and analyzing the variation in data, MMM can attribute changes in sales to specific factors like advertising, price changes, or external conditions such as weather ‚Äì precisely the variance of these factors. In turn, this explains why MMMs are typically very greedy on data.\n\nWhy Variance Matters\nVariance is essentially the ‚Äúspread‚Äù or ‚Äúdispersion‚Äù in data. When factors such as advertising spend, product pricing, and weather fluctuate, they create unique ‚Äúpatterns‚Äù in the data. These patterns allow MMM to distinguish the unique contribution of each factor to the overall sales. The model then estimates each variable‚Äôs impact by looking at how variations in these variables align with variations in sales over time.\nTo illustrate, imagine observing the temperature in a city where ice cream is sold. If the temperature were always a constant 25¬∞C, there would be no variance in the temperature, and the model couldn‚Äôt estimate the effect of temperature on sales of the ice cream. However, if the temperature fluctuates the model can analyze how sales change as the temperature rises or falls, attributing a portion of the sales changes to temperature change.\n\n\nVariance and Independence\nAnother crucial aspect of variance is how independent it is across variables. If variables such as advertising spend and temperature are strongly correlated ‚Äì for example, if higher advertising spend always coincides with warmer weather ‚Äì it becomes harder for the model to distinguish their effects. This issue, called¬†multicollinearity, can obscure the true influence of each factor.\nIdeally, each variable should have its own distinct and independent variance to enable the model to disentangle their contributions clearly. This is one reason why MMMs often require large, granular datasets ‚Äì they help ensure sufficient variation and independence among factors.\n\n\nVariance as the Key to Disentangling\nIn summary, variance is the foundation of how MMMs work. By identifying and analyzing differences in data, the model can separate the effects of multiple factors on sales. More variance means better opportunities to isolate these effects, making high-quality, diverse data essential for effective modeling. This ability to leverage variance is what gives MMMs their ‚Äúmagic‚Äù when it comes to attributing outcomes.\n\n\n\n\n\n\nThis post does not strive for statistical correctness. It should rather provide an intuitional view on how it works.\n\n\n\n\n\n\nGiving Intuition - Ice Cream\nTo demonstrate this in a simple example, let‚Äôs take an ice cream company and see how MMM might work to disentangle the effects of advertising, temperature, and price on sales.\n\nData Exploration\nIn this example, we‚Äôll simulate weekly ice cream sales data over three years (152 weeks) along with three explanatory variables:\n\nadvertising spend,\naverage weekly temperature,\nand the price of ice cream.\n\nThe ice creams sales (dependent variable) we want to explain by the three variables above (independent variables).\nTo not over-complicate things, in this example we assume the ice cream is sold in a market with warm temperatures (20¬∞C - 35¬∞C) across the year. Likewise we take the advertising spend into consideration, which is usually not best practice due to seasonality of media costs. That‚Äôs why one actually should use an activity metric. But in this example, for the sake of intuition, we remain with the spend. Furthermore the three independent variables are correlated to a a minimum.\n\n\nExploration of Ice Cream Sales\n\n\n\n\n\n\n\n\n\nThis is the time series of the sales of ice cream over 152 consecutive weeks. We can see lots of variation (weekly ups and downs of the sales). Typically, variation is captured using standardized metrics in statistics. Let‚Äôs explore this further.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\n\nnumeric\nsales\n0\n1\n786.3433\n142.7682\n455.6699\n687.173\n786.4601\n876.618\n1186.034\n‚ñÇ‚ñÜ‚ñá‚ñÖ‚ñÅ\n\n\n\n\n\nThe average weekly sales amount to 786 Euros, with a standard deviation of 142 Euros. This indicates that, on average, weekly sales fluctuate by approximately ¬±142 Euros around the mean. In other words, most weeks (about 68%, assuming a normal distribution) see sales between¬†644 Euros and 928 Euros.\nFurther more we can see the min (percentile 0) and max (percentile 100), giving us the range of the variation, from 455 Euros to 1186 Euros.\n\n\nConnection with Sales\nNo we need to go one step further and check the bi-variate connection of each factor impacting the sales. To visually inspect the connection properly, in statistics it is very common to use a scatter plot. Since ice cream sales is the dependent variable, we put this on the y-axis and the other variables on the x-axis.\n\nSales - TemperatureSales - Ad SpendSales - Price\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can clearly see: the warmer it is, the higher the sales. But also: the more is spent in advertising.\nAnd intuitively: the higher the price, the less the sales.\n\n\nCreating Intuition\nNow there is the problem going further: how can the model, which explains overall sales know, what is driven by what impacting factor and to what extend? As we already learned: it is about the variation. We will know give intuition about this concept and how it helps to disentangle the effects.\nTherefore we will calculate the average of each indepentent variable and then for each week check if it is above average or below average. For each week and variable, the we calculate an indicator variables, showing if the actual value in the respective week is above or below the average. This information will be transformed into 1 and 0 accordingly. And then we paste the information in one string, and simply count the occurrence. The order of the string is: ‚Äútemperature above everage‚Äù, ‚Äúad_spend_above_average‚Äù and ‚Äúprice_above_average‚Äù.\nLets see the result.\n\n\n\n\n\ncombination\nn\n\n\n\n\n0 0 0\n16\n\n\n0 0 1\n19\n\n\n0 1 0\n20\n\n\n0 1 1\n20\n\n\n1 0 0\n21\n\n\n1 0 1\n17\n\n\n1 1 0\n17\n\n\n1 1 1\n22\n\n\n\n\n\nHow to read this?\nThere is 22 cases in the data, where all the independent variables are above its average (1 1 1). And there is almost all possible combinations of being a variable above or below its average, e.g.¬†16 occurences, where all thre independent variables are below average.\nNow what we want to do this is, per group, add the average sales of this group.\n\n\n\n\n\ncombination\naverage_sales\n\n\n\n\n0 0 0\n707.8060\n\n\n0 0 1\n619.2067\n\n\n0 1 0\n824.0825\n\n\n0 1 1\n701.2840\n\n\n1 0 0\n867.8043\n\n\n1 0 1\n818.0238\n\n\n1 1 0\n937.6542\n\n\n1 1 1\n811.6645\n\n\n\n\n\nThats very interesting. In the 16 weeks, where all variables are below its average, the average sales are 707,81 Euro. If the price increases above its average, the sales drops even more to 619,21 Euros (I would say, this forms the worst conditions for ice cream sales: colder temperatures, lower advertising and higher prices). Likewise, if it is warmer than the average, and the sales are supported by advertising and the prices are decreasing, then we see the hightest sales of 937,65 Euros.\nNow lets make a twist, and arrange not by the combination but the average sales.\n\n\n\n\n\ncombination\naverage_sales\n\n\n\n\n0 0 1\n619.2067\n\n\n0 1 1\n701.2840\n\n\n0 0 0\n707.8060\n\n\n1 1 1\n811.6645\n\n\n1 0 1\n818.0238\n\n\n0 1 0\n824.0825\n\n\n1 0 0\n867.8043\n\n\n1 1 0\n937.6542\n\n\n\n\n\nWe can see that we see the ‚Äú1‚Äù at the start of the combination, indicating the weather, is rather at the bottom. Hence we can generalize: the warmer, the more ice cream sold. We can on the opposite see, the negative impact of the price. For the ad spend it is not so clear. What we can conclude here is, that the model will most likley come to the conclusion, that the price as such as a negative impact (negativ sign). And also that temperature will most likely have the strongest positive impact on sales.\n\n\nActual Model\nLets check the assumption from the previous chapter and create the model.\n\nNot StandardizedStandardized\n\n\n\n\n\nCall:\nlm(formula = sales ~ (temperature) + (ad_spend) + (price), data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-319.80  -62.19   -1.21   59.89  236.74 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  4.984e+02  6.653e+01   7.491 5.73e-12 ***\ntemperature  1.907e+01  1.793e+00  10.635  &lt; 2e-16 ***\nad_spend     3.615e-02  7.156e-03   5.053 1.27e-06 ***\nprice       -1.457e+02  1.766e+01  -8.249 8.02e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 95.06 on 148 degrees of freedom\nMultiple R-squared:  0.5654,    Adjusted R-squared:  0.5566 \nF-statistic: 64.19 on 3 and 148 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\nCall:\nlm(formula = sales ~ scale(temperature) + scale(ad_spend) + scale(price), \n    data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-319.80  -62.19   -1.21   59.89  236.74 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         786.343      7.711 101.982  &lt; 2e-16 ***\nscale(temperature)   82.400      7.748  10.635  &lt; 2e-16 ***\nscale(ad_spend)      39.222      7.763   5.053 1.27e-06 ***\nscale(price)        -63.979      7.756  -8.249 8.02e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 95.06 on 148 degrees of freedom\nMultiple R-squared:  0.5654,    Adjusted R-squared:  0.5566 \nF-statistic: 64.19 on 3 and 148 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nThe best way to compare the coefficients is the standardized view, as each independent variable has a different scale (e.g., euros, degrees Celsius). Standardization brings all variables onto the same scale by centering them around their mean and dividing by their standard deviation. This ensures that the effects are comparable, regardless of their original units. A higher standardized coefficient indicates which factor has the strongest influence, independent of its initial scale.\nThe model results confirm our assumptions.¬†Temperature¬†has the strongest positive impact on sales, with a standardized coefficient of¬†82.4, followed by¬†advertising spend¬†at¬†39.2.¬†Price, as expected, has a negative impact, with a coefficient of¬†-63.98, meaning higher prices significantly reduce sales. All these coefficients are statistically significant at the¬†p &lt; 0.001level, showing robust relationships.\nThe model explains approximately¬†56.5% of the variation¬†in sales (R-squared = 0.5654) and has a residual standard error of¬†95.06. The explanation of variance is not the best, and I would be rather careful with this model. Obviously there is sales-driving factors, which are not captured in the model (e.g.¬†could be the friendliness of the sales staff, the selling place, but also the economic situation of the clients).\nIn summary, warmer temperatures and increased advertising positively influence sales, while higher prices reduce them, with temperature being the dominant driver.\n\n\n\nConclusion\nThis post aimed to provide an intuitive understanding of how Marketing Mix Models disentangle effects. By leveraging variance and observing patterns in data, MMM can quantify the impact of different factors like temperature, advertising, and price on sales. Standardizing variables ensures fair comparisons of their influence, while analyzing combinations of factors reveals deeper insights into their interactions.\nIn practice, MMMs are invaluable tools for understanding what drives sales, but their accuracy depends on data quality and variance. By applying these principles, businesses can make more informed marketing decisions."
  }
]